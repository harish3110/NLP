{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Stemming:\n",
    "\n",
    "- Rule based/ heuristic approach to stemming forms to its root form. Uses crude heuristics to stem to root form.\n",
    "- Types of popular stemmers:\n",
    "    - Porter Stemmer\n",
    "    - Snowball stemmer(Porter 2)\n",
    "    - Lancaster Stemmer\n",
    "    \n",
    "- ***Since the stemming is a rule based approach the final stems could be faulted as it can lead to overstemming or understemming***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"It is important to by very pythonly & % / while you are pythoning with python. All pythoners have pythoned poorly at least once.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of stemming algorithms:\n",
    "\n",
    "1. Porter Stemmer: \n",
    "A gentle stemming algorithm. This is ***unused*** nowadays.\n",
    "\n",
    "2. Snowball Stemmer: (a.k.a Porter 2)\n",
    "Aggressive porter stemmer algorithm. Also has a ***faster computation****.\n",
    "\n",
    "3. Lancaster Stemmer:\n",
    "Most aggressive stemmer in comparison. Also the ***fastest*** stemmer out of the three."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating multiple types of stemmers on scikit-learn\n",
    "ps = PorterStemmer()\n",
    "ss = SnowballStemmer(\"english\")\n",
    "ls = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " 'is',\n",
       " 'important',\n",
       " 'to',\n",
       " 'by',\n",
       " 'very',\n",
       " 'pythonly',\n",
       " '&',\n",
       " '%',\n",
       " '/',\n",
       " 'while',\n",
       " 'you',\n",
       " 'are',\n",
       " 'pythoning',\n",
       " 'with',\n",
       " 'python',\n",
       " '.',\n",
       " 'All',\n",
       " 'pythoners',\n",
       " 'have',\n",
       " 'pythoned',\n",
       " 'poorly',\n",
       " 'at',\n",
       " 'least',\n",
       " 'once',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word Tokenizer\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It is important to by very pythonly & % / while you are pythoning with python.',\n",
       " 'All pythoners have pythoned poorly at least once.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence tokenizer\n",
    "sentence = sent_tokenize(new_text)\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porter stemmer\n",
    "stemmed_words_ps = []\n",
    "\n",
    "for w in words:\n",
    "    stemmed_words_ps.append(ps.stem(w))\n",
    "\n",
    "# stemmed_words_ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original input: It is important to by very pythonly & % / while you are pythoning with python. All pythoners have pythoned poorly at least once. \n",
      "\n",
      "The porter stemmer output: It is import to by veri pythonli & % / while you are python with python . all python have python poorli at least onc .\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original input: {new_text} \\n\")\n",
    "print(f\"The porter stemmer output: {' '.join(stemmed_words_ps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original input: It is important to by very pythonly & % / while you are pythoning with python. All pythoners have pythoned poorly at least once. \n",
      "\n",
      "The snowball stemmer output: it is import to by veri python & % / while you are python with python . all python have python poor at least onc .\n"
     ]
    }
   ],
   "source": [
    "#Snowball stemmer\n",
    "stemmed_words_ss = []\n",
    "\n",
    "for w in words:\n",
    "    stemmed_words_ss.append(ss.stem(w))\n",
    "\n",
    "# stemmed_words_ss\n",
    "print(f\"The original input: {new_text} \\n\")\n",
    "print(f\"The snowball stemmer output: {' '.join(stemmed_words_ss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original input: It is important to by very pythonly & % / while you are pythoning with python. All pythoners have pythoned poorly at least once. \n",
      "\n",
      "The lancaster stemmer output: it is import to by very python & % / whil you ar python with python . al python hav python poor at least ont .\n"
     ]
    }
   ],
   "source": [
    "#Lancaster stemmer\n",
    "stemmed_words_ls = []\n",
    "\n",
    "for w in words:\n",
    "    stemmed_words_ls.append(ls.stem(w))\n",
    "\n",
    "# stemmed_words_ls\n",
    "print(f\"The original input: {new_text} \\n\")\n",
    "print(f\"The lancaster stemmer output: {' '.join(stemmed_words_ls)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>porter_stemmer</th>\n",
       "      <th>lancaster_stemmer</th>\n",
       "      <th>snowball_stemmer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>It</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>important</td>\n",
       "      <td>import</td>\n",
       "      <td>import</td>\n",
       "      <td>import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>very</td>\n",
       "      <td>veri</td>\n",
       "      <td>very</td>\n",
       "      <td>veri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pythonly</td>\n",
       "      <td>pythonli</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "      <td>&amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>%</td>\n",
       "      <td>%</td>\n",
       "      <td>%</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>while</td>\n",
       "      <td>while</td>\n",
       "      <td>whil</td>\n",
       "      <td>while</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>are</td>\n",
       "      <td>are</td>\n",
       "      <td>ar</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pythoning</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>All</td>\n",
       "      <td>all</td>\n",
       "      <td>al</td>\n",
       "      <td>all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pythoners</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>have</td>\n",
       "      <td>have</td>\n",
       "      <td>hav</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pythoned</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>poorly</td>\n",
       "      <td>poorli</td>\n",
       "      <td>poor</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "      <td>least</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>once</td>\n",
       "      <td>onc</td>\n",
       "      <td>ont</td>\n",
       "      <td>onc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_word porter_stemmer lancaster_stemmer snowball_stemmer\n",
       "0             It             It                it               it\n",
       "1             is             is                is               is\n",
       "2      important         import            import           import\n",
       "3             to             to                to               to\n",
       "4             by             by                by               by\n",
       "5           very           veri              very             veri\n",
       "6       pythonly       pythonli            python           python\n",
       "7              &              &                 &                &\n",
       "8              %              %                 %                %\n",
       "9              /              /                 /                /\n",
       "10         while          while              whil            while\n",
       "11           you            you               you              you\n",
       "12           are            are                ar              are\n",
       "13     pythoning         python            python           python\n",
       "14          with           with              with             with\n",
       "15        python         python            python           python\n",
       "16             .              .                 .                .\n",
       "17           All            all                al              all\n",
       "18     pythoners         python            python           python\n",
       "19          have           have               hav             have\n",
       "20      pythoned         python            python           python\n",
       "21        poorly         poorli              poor             poor\n",
       "22            at             at                at               at\n",
       "23         least          least             least            least\n",
       "24          once            onc               ont              onc\n",
       "25             .              .                 .                ."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Comparing words and stemmed_words to understand stemming\n",
    "\n",
    "df = pd.DataFrame({'original_word': words, 'porter_stemmer': stemmed_words_ps, 'lancaster_stemmer': stemmed_words_ls, 'snowball_stemmer': stemmed_words_ss})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lemmatization\n",
    "\n",
    "A very similar operation to stemming is called lemmatizing. The major difference between these is, as you saw earlier, stemming can often create non-existent words, whereas lemmas are actual words.\n",
    "\n",
    "So, your root stem, meaning the word you end up with, is not something you can just look up in a dictionary, but you can look up a lemma.\n",
    "\n",
    "Some times you will wind up with a very similar word, but sometimes, you will wind up with a completely different word. Let's see some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/harish3110/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "corpora : corpus\n",
      "better : good\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer \n",
    "  \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "  \n",
    "print(\"rocks :\", lemmatizer.lemmatize(\"rocks\")) \n",
    "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\")) \n",
    "  \n",
    "# a denotes adjective in \"pos\" \n",
    "print(\"better :\", lemmatizer.lemmatize(\"better\", pos =\"a\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "cactus\n",
      "goose\n",
      "rock\n",
      "python\n",
      "good\n",
      "best\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(lemmatizer.lemmatize(\"cats\"))\n",
    "print(lemmatizer.lemmatize(\"cacti\"))\n",
    "print(lemmatizer.lemmatize(\"geese\"))\n",
    "print(lemmatizer.lemmatize(\"rocks\"))\n",
    "print(lemmatizer.lemmatize(\"python\"))\n",
    "print(lemmatizer.lemmatize(\"better\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"best\", pos=\"a\"))\n",
    "print(lemmatizer.lemmatize(\"run\"))\n",
    "print(lemmatizer.lemmatize(\"run\",'v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
